{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable, List, Optional\n",
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "from babydragon.memory.kernels.memory_kernel import MemoryKernel\n",
    "from babydragon.memory.indexes.python_index import PythonIndex\n",
    "from babydragon.chat.memory_chat import FifoChat\n",
    "import babydragon\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babydragon_path = os.path.dirname(os.path.abspath(babydragon.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex= PythonIndex(babydragon_path, name=\"babyd_index_parallel\", minify_code=False, load = True, max_workers=16, backup= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex.faiss_query(\"open ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babykernel = MemoryKernel(babyindex, name=\"babyd_kernel_parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = FifoChat(model= \"gpt-3.5-turbo\", index_dict = {\"babyindex\":babyindex}, name=\"babyd_chatbot\", max_fifo_memory=1000, max_index_memory = 2500, max_output_tokens= 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.reply(\"What is a MemoryThread?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babydragon.tasks.llm_task import LLMReader, LLMWriter\n",
    "from babydragon.chat.chat import Chat\n",
    "\n",
    "system_prompt = \"You are a helfpul summarizer. The user will input some code from the babydragon package, you have to write a summary of what the code does for future documentation use.\\n\\n\"\n",
    "\n",
    "\n",
    "def summary_prompt(paragraph):\n",
    "    return f\"Summarize the following paragraph:\\n\\n{paragraph}\\n\\nSummary:\"\n",
    "\n",
    "\n",
    "summarizer = Chat(system_prompt=system_prompt, user_prompt=summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = babyindex\n",
    "path = [[x] for x in range(len(target_index.values))]\n",
    "# path = [list(range(len(target_index.values)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_task = LLMWriter(\n",
    "    index=target_index,\n",
    "    path=path,\n",
    "    chatbot=summarizer,\n",
    "    max_workers=12,\n",
    "    task_id=\"summary_babydragon\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " There is no paragraph provided to summarize. Please provide the necessary input."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call OpenAI API...RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " from typing import Optional\n",
       "\n",
       "import tiktoken\n",
       "import os\n",
       "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
       "from babydragon.processors.parsers.python_parser import PythonParser\n",
       "\n",
       "\n",
       "class PythonIndex(MemoryIndex, PythonParser):\n",
       "    def __init__(\n",
       "        self,\n",
       "        directory_path: str,\n",
       "        name: str = \"python_index\",\n",
       "        save_path: Optional[str] = None,\n",
       "        load: bool = False,\n",
       "        minify_code: bool = False,\n",
       "        remove_docstrings: bool = False,\n",
       "        tokenizer: Optional[tiktoken.Encoding] = None,\n",
       "        max_workers: int = 1,\n",
       "        backup: bool = False,\n",
       "    ):\n",
       "        # # Initialize the MemoryIndex\n",
       "        # MemoryIndex.__init__(\n",
       "        #     self,\n",
       "        #     name=name,\n",
       "        #     save_path=save_path,\n",
       "        #     load=load,\n",
       "        #     tokenizer=tokenizer,\n",
       "        #     max_workers=max_workers,\n",
       "        #     backup\n",
       "        # )\n",
       "        # Initialize the PythonParser\n",
       "        PythonParser.__init__(\n",
       "            self,\n",
       "            directory_path=directory_path,\n",
       "            minify_code=minify_code,\n",
       "            remove_docstrings=remove_docstrings,\n",
       "        )\n",
       "        #check if load folder exists\n",
       "        if save_path is None:\n",
       "            save_path = \"storage\"\n",
       "        load_directory = os.path.join(save_path, name)\n",
       "        loadcheck = not load or not os.path.exists(load_directory)\n",
       "        if load and not os.path.exists(load_directory):\n",
       "            print(\"No python-index found even if load=True, indexing from scratch\")\n",
       "        if loadcheck:\n",
       "            # Extract functions and classes source code\n",
       "            function_source_codes, class_source_codes, _, _ = self.process_directory()\n",
       "            print(\n",
       "                \"Indexing {} functions and {} classes\".format(\n",
       "                    len(function_source_codes), len(class_source_codes)\n",
       "                )\n",
       "            )\n",
       "            # Concatenate function and class source code and index them\n",
       "            codes = function_source_codes + class_source_codes\n",
       "            load = False\n",
       "\n",
       "         # Initialize the MemoryIndex\n",
       "        MemoryIndex.__init__(\n",
       "            self,\n",
       "            name=name,\n",
       "            values=codes if loadcheck else None,\n",
       "            save_path=save_path,\n",
       "            load=load,\n",
       "            tokenizer=tokenizer,\n",
       "            max_workers=max_workers,\n",
       "            backup=backup,\n",
       "        )"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The code is importing necessary modules from the babydragon package and defining a class called PythonIndex. This class takes in various parameters such as directory path, minimum number of workers, and backup status. It initializes a MemoryIndex and PythonParser, and processes the directory to extract function and class source codes. It then concatenates the source codes and indexes them. The indexed values are saved and loaded if specified."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-task 67 executed in 4.56 seconds.\n",
      "Sub-task 67 results saved in 0.00 seconds.\n",
      "Sub-task 68 executed in 0.00 seconds.\n",
      "Sub-task 68 results saved in 0.00 seconds.\n",
      "Trying to call OpenAI API...RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " def create_paths(\n",
       "    self, embeddings: np.ndarray, num_clusters: int\n",
       ") -> List[List[int]]:\n",
       "    raise NotImplementedError\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The function named \"create_paths\" takes in embeddings as a numpy array and a number of clusters as an integer, and is expected to return a list of lists of integers. However, the implementation of this function is not yet provided and raises a \"NotImplementedError\" when called."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-task 69 executed in 4.00 seconds.\n",
      "Sub-task 69 results saved in 0.00 seconds.\n",
      "Trying to call OpenAI API...RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "\n",
      "Trying to call OpenAI API...RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " def create_paths(\n",
       "    self, embeddings: np.ndarray, num_clusters: int\n",
       ") -> List[List[int]]:\n",
       "    clusterer = hdbscan.HDBSCAN(min_cluster_size=num_clusters)\n",
       "    cluster_assignments = clusterer.fit_predict(embeddings)\n",
       "    paths = [[] for _ in range(num_clusters)]\n",
       "    for i, cluster in enumerate(cluster_assignments):\n",
       "        paths[cluster].append(i)\n",
       "    paths = [path for path in paths if path]\n",
       "    return paths\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The code defines a function called \"create_paths\" that takes an array of embeddings and a number of clusters as input and returns a list of lists containing cluster assignments. It first creates a clusterer object using the HDBSCAN algorithm and uses it to assign each embedding to a cluster. Then, it creates an empty list of paths for each cluster and appends the indices of embeddings belonging to each cluster to the corresponding path list. Finally, it removes any empty path lists and returns the remaining non-empty path lists."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-task 70 executed in 5.40 seconds.\n",
      "Sub-task 70 results saved in 0.00 seconds.\n",
      "Trying to call OpenAI API...RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " def create_paths(\n",
       "    self, A: np.ndarray, num_clusters: int\n",
       ") -> List[List[int]]:\n",
       "    n_samples = A.shape[0]\n",
       "    n_neighbors = min(n_samples - 1, 10)  # Set n_neighbors to min(n_samples - 1, 10)\n",
       "    spectral_clustering = SpectralClustering(\n",
       "        n_clusters=num_clusters,\n",
       "        affinity=\"precomputed\",\n",
       "        n_neighbors=n_neighbors,\n",
       "        random_state=42,\n",
       "    )\n",
       "    cluster_assignments = spectral_clustering.fit_predict(A)\n",
       "    paths = [[] for _ in range(num_clusters)]\n",
       "    for i, cluster in enumerate(cluster_assignments):\n",
       "        paths[cluster].append(i)\n",
       "    paths = [path for path in paths if path]\n",
       "    return paths\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The code defines a function that takes a numpy array A and an integer num_clusters as input and returns a list of paths. It sets the number of neighbors for SpectralClustering to the minimum of the number of samples minus one and 10. It uses SpectralClustering to assign clusters to the data points and creates a list of paths for each cluster that contains the indices of the points assigned to that cluster. The function returns a list of non-empty paths."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-task 71 executed in 3.20 seconds.\n",
      "Sub-task 71 results saved in 0.00 seconds.\n",
      "Trying to call OpenAI API...RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " \n",
       "\n",
       "def calc_shgo_mode(scores: List[float]) -> float:\n",
       "    def objective(x):\n",
       "        return -estimate_pdf(scores)(x)\n",
       "\n",
       "    bounds = [(min(scores), max(scores))]\n",
       "    result = scipy.optimize.shgo(objective, bounds)\n",
       "    return result.x\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The code defines a function, `calc_shgo_mode`, that takes a list of numbers and calculates the mode using the shgo optimization algorithm from the Scipy library. The function first defines another function called `objective` that estimates the probability density function of the scores and uses it to find the mode. The mode is returned as a float value."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " from typing import List\n",
       "\n",
       "import hdbscan\n",
       "import numpy as np\n",
       "from sklearn.cluster import SpectralClustering\n",
       "\n",
       "\n",
       "class ClusterPaths:\n",
       "    def create_paths(\n",
       "        self, embeddings: np.ndarray, num_clusters: int\n",
       "    ) -> List[List[int]]:\n",
       "        raise NotImplementedError\n",
       "\n",
       "\n",
       "class HDBSCANPaths(ClusterPaths):\n",
       "    def create_paths(\n",
       "        self, embeddings: np.ndarray, num_clusters: int\n",
       "    ) -> List[List[int]]:\n",
       "        clusterer = hdbscan.HDBSCAN(min_cluster_size=num_clusters)\n",
       "        cluster_assignments = clusterer.fit_predict(embeddings)\n",
       "        paths = [[] for _ in range(num_clusters)]\n",
       "        for i, cluster in enumerate(cluster_assignments):\n",
       "            paths[cluster].append(i)\n",
       "        paths = [path for path in paths if path]\n",
       "        return paths\n",
       "\n",
       "\n",
       "class SpectralClusteringPaths(ClusterPaths):\n",
       "    def create_paths(\n",
       "        self, A: np.ndarray, num_clusters: int\n",
       "    ) -> List[List[int]]:\n",
       "        n_samples = A.shape[0]\n",
       "        n_neighbors = min(n_samples - 1, 10)  # Set n_neighbors to min(n_samples - 1, 10)\n",
       "        spectral_clustering = SpectralClustering(\n",
       "            n_clusters=num_clusters,\n",
       "            affinity=\"precomputed\",\n",
       "            n_neighbors=n_neighbors,\n",
       "            random_state=42,\n",
       "        )\n",
       "        cluster_assignments = spectral_clustering.fit_predict(A)\n",
       "        paths = [[] for _ in range(num_clusters)]\n",
       "        for i, cluster in enumerate(cluster_assignments):\n",
       "            paths[cluster].append(i)\n",
       "        paths = [path for path in paths if path]\n",
       "        return paths\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The code defines two classes, HDBSCANPaths and SpectralClusteringPaths, that inherit from the abstract class ClusterPaths. Both classes have a method create_paths that takes in embeddings or an adjacency matrix, and uses either HDBSCAN or SpectralClustering algorithm to cluster them into num_clusters clusters. The method returns a list of cluster assignments where each index in the list corresponds to a cluster and contains a list of indices that belong to that cluster."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-task 72 executed in 3.98 seconds.\n",
      "Sub-task 72 results saved in 0.00 seconds.\n",
      "Sub-task 73 executed in 0.00 seconds.\n",
      "Sub-task 73 results saved in 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " def objective(x):\n",
       "    return -estimate_pdf(scores)(x)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The given code defines a function named \"objective\" that takes a variable \"x\" as input and returns the negative estimated probability density function of \"scores\" at point \"x\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-task 74 executed in 0.50 seconds.\n",
      "Sub-task 74 results saved in 0.00 seconds.\n",
      "Trying to call OpenAI API...\n",
      "RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "Trying to call OpenAI API...RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " \n",
       "\n",
       "def estimate_pdf(scores: List[float]) -> callable:\n",
       "    pdf = scipy.stats.gaussian_kde(scores)\n",
       "    return pdf\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The code defines a function called \"estimate_pdf\" that takes in a list of float numbers called \"scores,\" uses the \"gaussian_kde\" function from the \"scipy.stats\" package to estimate the probability density function (PDF) based on the input scores, and returns the estimated PDF as a callable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-task 75 executed in 4.92 seconds.\n",
      "Sub-task 75 results saved in 0.00 seconds.\n",
      "Trying to call OpenAI API...RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " \n",
       "\n",
       "def sort_paths_by_mode_distance(\n",
       "    paths, memory_kernel, distance_metric: str = \"cosine\"\n",
       ") -> List[List[int]]:\n",
       "    sorted_paths = []\n",
       "    for i, path in enumerate(paths):\n",
       "        cluster_embeddings = [memory_kernel.node_embeddings[i] for i in path]\n",
       "        cluster_embeddings = np.array(cluster_embeddings)\n",
       "        cluster_mean = np.mean(cluster_embeddings, axis=0)\n",
       "        if distance_metric == \"cosine\" or distance_metric == \"guassian\":\n",
       "            scores = [\n",
       "                (i, cosine(cluster_mean, emb))\n",
       "                for i, emb in zip(path, cluster_embeddings)\n",
       "            ]\n",
       "        elif distance_metric == \"euclidean\":\n",
       "            scores = [\n",
       "                (i, np.linalg.norm(cluster_mean - emb))\n",
       "                for i, emb in zip(path, cluster_embeddings)\n",
       "            ]\n",
       "        score_values = [score for _, score in scores]  # Extract score values\n",
       "        mu = calc_shgo_mode(score_values)\n",
       "        sigma = np.std(score_values)\n",
       "        if distance_metric == \"guassian\":\n",
       "            scores = [\n",
       "                (i, np.exp(-((x - mu) ** 2) / (2 * sigma**2))) for i, x in scores\n",
       "            ]\n",
       "        # Sort path by score\n",
       "        sorted_path_and_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
       "        sorted_path = [x[0] for x in sorted_path_and_scores]\n",
       "        sorted_paths.append(sorted_path)\n",
       "    return sorted_paths\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The 'sort_paths_by_mode_distance' function sorts a list of node paths based on their similarity score calculated using the mean of their embeddings and a specified distance metric. The sorted paths are returned as a list. If the distance metric is \"gaussian\", scores are normalized using a gaussian function."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-task 76 executed in 4.09 seconds.\n",
      "Sub-task 76 results saved in 0.00 seconds.\n",
      "Trying to call OpenAI API...\n",
      "RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "Trying to call OpenAI API...RateLimiter: Waiting for 3.00 seconds before next call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "babyindex_summary = summary_task.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex_summary.faiss_query(\"OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_summary = FifoChat(model= \"gpt-3.5-turbo\", index_dict = {\"babyindex_summary\":babyindex_summary}, name=\"babyd_chatbot_summary\", max_fifo_memory=1000, max_index_memory = 2500, max_output_tokens= 400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
