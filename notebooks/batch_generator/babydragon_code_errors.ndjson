{"error": {"message": "This model's maximum context length is 16385 tokens. However, you requested 17181 tokens (13181 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 16385 tokens. However, you requested 18323 tokens (14323 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 16385 tokens. However, your messages resulted in 41460 tokens. Please reduce the length of the messages.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
