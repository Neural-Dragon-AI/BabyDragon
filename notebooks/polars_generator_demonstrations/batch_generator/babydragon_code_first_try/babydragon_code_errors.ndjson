{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4226 tokens (226 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4245 tokens (245 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4134 tokens (134 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4133 tokens (133 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4172 tokens (172 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5024 tokens (1024 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4136 tokens (136 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4252 tokens (252 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4325 tokens (325 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4308 tokens (308 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4937 tokens (937 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4136 tokens (136 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4254 tokens (254 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4249 tokens (249 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4308 tokens (308 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4903 tokens (903 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4157 tokens (157 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4418 tokens (418 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4189 tokens (189 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4474 tokens (474 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4223 tokens (223 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4221 tokens (221 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4227 tokens (227 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4266 tokens (266 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4137 tokens (137 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4637 tokens (637 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4194 tokens (194 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4194 tokens (194 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4258 tokens (258 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4369 tokens (369 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4241 tokens (241 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4142 tokens (142 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4101 tokens (101 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4197 tokens (197 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4184 tokens (184 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4110 tokens (110 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4202 tokens (202 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4496 tokens (496 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4362 tokens (362 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4387 tokens (387 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4260 tokens (260 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4227 tokens (227 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4152 tokens (152 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4226 tokens (226 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5615 tokens (1615 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4259 tokens (259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4223 tokens (223 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4331 tokens (331 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4200 tokens (200 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4228 tokens (228 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4256 tokens (256 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4242 tokens (242 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4337 tokens (337 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4338 tokens (338 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4141 tokens (141 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4201 tokens (201 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4442 tokens (442 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4188 tokens (188 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4227 tokens (227 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4103 tokens (103 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4333 tokens (333 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4106 tokens (106 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4137 tokens (137 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4152 tokens (152 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4184 tokens (184 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4142 tokens (142 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4121 tokens (121 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4187 tokens (187 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4237 tokens (237 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4426 tokens (426 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4127 tokens (127 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4138 tokens (138 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4105 tokens (105 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4164 tokens (164 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4213 tokens (213 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4137 tokens (137 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4152 tokens (152 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4133 tokens (133 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4100 tokens (100 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4212 tokens (212 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4159 tokens (159 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4208 tokens (208 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4234 tokens (234 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4351 tokens (351 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4107 tokens (107 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4164 tokens (164 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4152 tokens (152 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4166 tokens (166 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4100 tokens (100 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4100 tokens (100 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4106 tokens (106 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4360 tokens (360 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4117 tokens (117 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4331 tokens (331 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4174 tokens (174 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4147 tokens (147 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4131 tokens (131 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4126 tokens (126 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4130 tokens (130 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4127 tokens (127 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4127 tokens (127 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4121 tokens (121 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4115 tokens (115 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4115 tokens (115 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4113 tokens (113 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4114 tokens (114 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4114 tokens (114 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4114 tokens (114 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4169 tokens (169 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4107 tokens (107 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4143 tokens (143 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4196 tokens (196 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4256 tokens (256 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4227 tokens (227 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4283 tokens (283 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4165 tokens (165 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4307 tokens (307 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4213 tokens (213 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4134 tokens (134 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4117 tokens (117 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4121 tokens (121 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4121 tokens (121 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 984dfac99fd95089868f0c28aa399acb in your message.)", "type": "server_error", "param": null, "code": null}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4127 tokens (127 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4120 tokens (120 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4130 tokens (130 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 93e21a6d2c80250480033e3a64118934 in your message.)", "type": "server_error", "param": null, "code": null}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4137 tokens (137 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4130 tokens (130 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4130 tokens (130 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4133 tokens (133 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4126 tokens (126 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4136 tokens (136 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4250 tokens (250 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4106 tokens (106 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4132 tokens (132 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4255 tokens (255 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4108 tokens (108 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4199 tokens (199 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4121 tokens (121 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4120 tokens (120 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4117 tokens (117 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4121 tokens (121 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4127 tokens (127 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4134 tokens (134 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4121 tokens (121 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4126 tokens (126 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6632408578cb17be5ba82cad48ecb1a2 in your message.)", "type": "server_error", "param": null, "code": null}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4126 tokens (126 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4126 tokens (126 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4132 tokens (132 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b328b034dc96e05ffd379ebc99952b11 in your message.)", "type": "server_error", "param": null, "code": null}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4133 tokens (133 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e380119e8e276f3bc0a9414ebb497b37 in your message.)", "type": "server_error", "param": null, "code": null}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4335 tokens (335 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4236 tokens (236 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4235 tokens (235 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4351 tokens (351 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4134 tokens (134 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4117 tokens (117 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4121 tokens (121 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4121 tokens (121 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4127 tokens (127 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4120 tokens (120 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4130 tokens (130 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 475786ac48304919d65189882d838ce9 in your message.)", "type": "server_error", "param": null, "code": null}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4134 tokens (134 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4117 tokens (117 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4117 tokens (117 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4131 tokens (131 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4130 tokens (130 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4130 tokens (130 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4133 tokens (133 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4126 tokens (126 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4136 tokens (136 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6e85f019ca54ac91eb3efda7d34681ac in your message.)", "type": "server_error", "param": null, "code": null}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
""
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4122 tokens (122 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4129 tokens (129 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 488f73325281f1fc97cd418d9888631a in your message.)", "type": "server_error", "param": null, "code": null}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4163 tokens (163 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4103 tokens (103 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4116 tokens (116 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5758 tokens (1758 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4388 tokens (388 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4304 tokens (304 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4990 tokens (990 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4116 tokens (116 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4098 tokens (98 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4108 tokens (108 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4136 tokens (136 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4174 tokens (174 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4232 tokens (232 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4106 tokens (106 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4180 tokens (180 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4107 tokens (107 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4135 tokens (135 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4210 tokens (210 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4109 tokens (109 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4135 tokens (135 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4109 tokens (109 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4108 tokens (108 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4108 tokens (108 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4152 tokens (152 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4652 tokens (652 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4288 tokens (288 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4280 tokens (280 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4185 tokens (185 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4187 tokens (187 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4294 tokens (294 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4113 tokens (113 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4272 tokens (272 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4108 tokens (108 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4137 tokens (137 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4338 tokens (338 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4249 tokens (249 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4225 tokens (225 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4450 tokens (450 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4463 tokens (463 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4240 tokens (240 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4267 tokens (267 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4116 tokens (116 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4215 tokens (215 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4166 tokens (166 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4224 tokens (224 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4407 tokens (407 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4428 tokens (428 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4726 tokens (726 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4365 tokens (365 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4390 tokens (390 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4159 tokens (159 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4148 tokens (148 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4327 tokens (327 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4100 tokens (100 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4104 tokens (104 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4155 tokens (155 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4267 tokens (267 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4115 tokens (115 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4153 tokens (153 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5658 tokens (1658 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4296 tokens (296 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4166 tokens (166 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4134 tokens (134 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4197 tokens (197 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4169 tokens (169 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5034 tokens (1034 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4694 tokens (694 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4263 tokens (263 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4228 tokens (228 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4099 tokens (99 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4167 tokens (167 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4101 tokens (101 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4114 tokens (114 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4132 tokens (132 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4181 tokens (181 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4285 tokens (285 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4262 tokens (262 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4393 tokens (393 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4227 tokens (227 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4205 tokens (205 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4237 tokens (237 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4187 tokens (187 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4564 tokens (564 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4488 tokens (488 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4147 tokens (147 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4598 tokens (598 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4218 tokens (218 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4863 tokens (863 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4194 tokens (194 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4199 tokens (199 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4238 tokens (238 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4284 tokens (284 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5020 tokens (1020 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4195 tokens (195 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4283 tokens (283 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4307 tokens (307 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4269 tokens (269 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4363 tokens (363 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4201 tokens (201 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4280 tokens (280 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4148 tokens (148 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4102 tokens (102 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4656 tokens (656 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4677 tokens (677 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4130 tokens (130 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4438 tokens (438 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5163 tokens (1163 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4244 tokens (244 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4168 tokens (168 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4190 tokens (190 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4457 tokens (457 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4218 tokens (218 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4131 tokens (131 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5015 tokens (1015 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4171 tokens (171 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4202 tokens (202 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4138 tokens (138 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4528 tokens (528 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4168 tokens (168 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4239 tokens (239 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4366 tokens (366 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4133 tokens (133 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5449 tokens (1449 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4199 tokens (199 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4222 tokens (222 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4281 tokens (281 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4112 tokens (112 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4127 tokens (127 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4112 tokens (112 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4216 tokens (216 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4226 tokens (226 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4098 tokens (98 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4313 tokens (313 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4130 tokens (130 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4136 tokens (136 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4111 tokens (111 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4183 tokens (183 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4241 tokens (241 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4337 tokens (337 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4175 tokens (175 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5176 tokens (1176 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4604 tokens (604 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4569 tokens (569 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4184 tokens (184 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4530 tokens (530 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4191 tokens (191 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4187 tokens (187 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4134 tokens (134 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4155 tokens (155 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5094 tokens (1094 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4191 tokens (191 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4190 tokens (190 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 02b645cdb3e240c440a925bb1ed28dbd in your message.)", "type": "server_error", "param": null, "code": null}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4124 tokens (124 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4115 tokens (115 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4115 tokens (115 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4225 tokens (225 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4301 tokens (301 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4220 tokens (220 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4235 tokens (235 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4134 tokens (134 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4598 tokens (598 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4569 tokens (569 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4170 tokens (170 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4524 tokens (524 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4662 tokens (662 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4410 tokens (410 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5158 tokens (1158 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4261 tokens (261 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4200 tokens (200 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4106 tokens (106 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4397 tokens (397 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4422 tokens (422 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4213 tokens (213 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4491 tokens (491 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4127 tokens (127 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4189 tokens (189 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5518 tokens (1518 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5057 tokens (1057 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4615 tokens (615 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5050 tokens (1050 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5782 tokens (1782 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4155 tokens (155 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5051 tokens (1051 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4099 tokens (99 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4938 tokens (938 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4244 tokens (244 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4240 tokens (240 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4157 tokens (157 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4180 tokens (180 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4932 tokens (932 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4139 tokens (139 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4118 tokens (118 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4517 tokens (517 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4123 tokens (123 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4944 tokens (944 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4100 tokens (100 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (125 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4183 tokens (183 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4120 tokens (120 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4166 tokens (166 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4153 tokens (153 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4097 tokens (97 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4192 tokens (192 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4226 tokens (226 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4296 tokens (296 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4110 tokens (110 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4191 tokens (191 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4127 tokens (127 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4261 tokens (261 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4117 tokens (117 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4135 tokens (135 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4178 tokens (178 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4187 tokens (187 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4100 tokens (100 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4411 tokens (411 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4181 tokens (181 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4181 tokens (181 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4119 tokens (119 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4243 tokens (243 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5079 tokens (1079 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4193 tokens (193 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4171 tokens (171 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4325 tokens (325 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4263 tokens (263 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4239 tokens (239 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4246 tokens (246 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4153 tokens (153 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4263 tokens (263 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4166 tokens (166 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4097 tokens (97 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4499 tokens (499 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4185 tokens (185 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4159 tokens (159 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4105 tokens (105 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4107 tokens (107 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4252 tokens (252 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4149 tokens (149 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4102 tokens (102 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4331 tokens (331 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4114 tokens (114 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4167 tokens (167 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4373 tokens (373 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4238 tokens (238 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4138 tokens (138 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4159 tokens (159 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4247 tokens (247 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4237 tokens (237 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4255 tokens (255 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4135 tokens (135 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4334 tokens (334 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4203 tokens (203 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4426 tokens (426 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4294 tokens (294 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4268 tokens (268 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4996 tokens (996 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4108 tokens (108 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4112 tokens (112 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4247 tokens (247 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4173 tokens (173 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4309 tokens (309 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4146 tokens (146 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4225 tokens (225 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4150 tokens (150 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 5110 tokens (1110 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4166 tokens (166 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4370 tokens (370 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4128 tokens (128 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 4097 tokens. However, you requested 4101 tokens (101 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
