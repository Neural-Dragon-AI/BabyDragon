{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable, List, Optional\n",
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "from babydragon.memory.kernels.memory_kernel import MemoryKernel\n",
    "from babydragon.memory.indexes.python_index import PythonIndex\n",
    "from babydragon.chat.memory_chat import FifoChat\n",
    "from babydragon.chat.chat import Chat\n",
    "import babydragon\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "babydragon_path = os.path.dirname(os.path.abspath(babydragon.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from storage/babyd_index_parallel\n"
     ]
    }
   ],
   "source": [
    "babyindex= PythonIndex(babydragon_path, name=\"babyd_index_parallel\", minify_code=False, load = True, max_workers=16, backup= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is available so using index prompts\n"
     ]
    }
   ],
   "source": [
    "chatbot = FifoChat(model= \"gpt-3.5-turbo\", index_dict = {\"babyindex\":babyindex}, name=\"babyd_chatbot\", max_index_memory = 2500, max_output_tokens= 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Chat.get_index_hints of <babydragon.chat.memory_chat.FifoChat object at 0x1612cc9d0>>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.user_prompt)\n",
    "print(chatbot.user_defined_user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'babyindex'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.current_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No user defined system prompt defaulting to default prompts\n"
     ]
    }
   ],
   "source": [
    "chatbot.set_current_index(None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call OpenAI API...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " What is a memoryindex"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " A `MemoryIndex` is a class used for creating an in-memory index that can be used for search and retrieval of data. It is a subclass of the `BaseIndex` class and is initialized with various parameters such as `name`, `values`, `embeddings`, `save_path`, `load`, `tokenizer`, `max_workers`, `backup`, and so on. The `MemoryIndex` class allows for the storage and retrieval of data without the need for a database or external storage."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'A `MemoryIndex` is a class used for creating an in-memory index that can be used for search and retrieval of data. It is a subclass of the `BaseIndex` class and is initialized with various parameters such as `name`, `values`, `embeddings`, `save_path`, `load`, `tokenizer`, `max_workers`, `backup`, and so on. The `MemoryIndex` class allows for the storage and retrieval of data without the need for a database or external storage.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.reply(\"What is a memoryindex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex.faiss_query(\"open ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babykernel = MemoryKernel(babyindex, name=\"babyd_kernel_parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = FifoChat(model= \"gpt-3.5-turbo\", index_dict = {\"babyindex\":babyindex}, name=\"babyd_chatbot\", max_fifo_memory=1000, max_index_memory = 2500, max_output_tokens= 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.reply(\"What is a MemoryThread?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babydragon.tasks.llm_task import LLMReader, LLMWriter\n",
    "from babydragon.chat.chat import Chat\n",
    "\n",
    "system_prompt = \"You are a helfpul summarizer. The user will input some code from the babydragon package, you have to write a summary of what the code does for future documentation use.\\n\\n\"\n",
    "\n",
    "\n",
    "def summary_prompt(paragraph):\n",
    "    return f\"Summarize the following paragraph:\\n\\n{paragraph}\\n\\nSummary:\"\n",
    "\n",
    "\n",
    "summarizer = Chat(system_prompt=system_prompt, user_prompt=summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = babyindex\n",
    "path = [[x] for x in range(len(target_index.values))]\n",
    "# path = [list(range(len(target_index.values)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_task = LLMWriter(\n",
    "    index=target_index,\n",
    "    path=path,\n",
    "    chatbot=summarizer,\n",
    "    max_workers=12,\n",
    "    task_id=\"summary_babydragon\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex_summary = summary_task.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex_summary.faiss_query(\"OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_summary = FifoChat(model= \"gpt-3.5-turbo\", index_dict = {\"babyindex_summary\":babyindex_summary}, name=\"babyd_chatbot_summary\", max_fifo_memory=1000, max_index_memory = 2500, max_output_tokens= 400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
