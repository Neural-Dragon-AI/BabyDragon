{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat and Prompter Class\n",
    "In this tutorial, we will demonstrate how to use the Chat and Prompter classes in the BabyDragon chatbot framework. These classes allow you to create a chatbot with a system and user prompt, and the ability to handle queries to multiple MemoryIndex through the index_dict.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. getting a response from the Cohere and OpenAi api\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babydragon.models.generators.cohere import cohere_response\n",
    "from babydragon.models.generators.chatgpt import chatgpt_response\n",
    "from babydragon.utils.chatml import mark_question\n",
    "import openai\n",
    "openai.api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'What is the meaning of life'}]\n"
     ]
    }
   ],
   "source": [
    "questions = \"What is the meaning of life\"\n",
    "marked_questions = [mark_question(questions)]\n",
    "print(marked_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call Cohere API... using model: command-nightly\n",
      "([cohere.Generation {\n",
      "\tid: 384c975b-4cd5-4811-99d0-8bfb6cc38299\n",
      "\tprompt:  #USER: What is the meaning of life\n",
      "\ttext: \n",
      "The meaning of life is a philosophical question that has been debated throughout history. Different people may have different perspectives on what the meaning of life is, or if there is a meaning at all. Some may believe that the purpose of life is to seek happiness, others may believe that it is to fulfil a specific destiny or purpose, and still others may argue that life has no inherent meaning. Ultimately, the meaning of life is a subjective concept that may be shaped by one's personal beliefs and experience.\n",
      "\tlikelihood: None\n",
      "\ttoken_likelihoods: None\n",
      "}], True)\n"
     ]
    }
   ],
   "source": [
    "response = cohere_response(prompt = marked_questions, model = \"command-nightly\", max_tokens = 1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call OpenAI API...\n"
     ]
    }
   ],
   "source": [
    "response = chatgpt_response(prompt = marked_questions, model = \"gpt-3.5-turbo\", max_tokens = 1000)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import necessary modules\n",
    "Before we begin, let's import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Optional, Union\n",
    "from babydragon.chat.base_chat import BaseChat, Prompter\n",
    "from babydragon.chat.prompts.default_prompts import (INDEX_HINT_PROMPT,\n",
    "                                                     INDEX_SYSTEM_PROMPT,\n",
    "                                                     QUESTION_INTRO)\n",
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "from babydragon.chat.chat import Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Chat class\n",
    "Create an instance of the Chat class with the desired parameters. In this example, we will use the default model, gpt-3.5-turbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_instance = Chat(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the system and user prompts\n",
    "Define the system and user prompts to guide the chatbot. You can either use the default prompts provided by the framework or define your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"I am a helpful assistant. How may I help you today?\"\n",
    "def user_prompt(message: str) -> str:\n",
    "    return f\"User: {message}\"\n",
    "\n",
    "chat_instance.update_system_prompt(system_prompt)\n",
    "chat_instance.update_user_prompt(user_prompt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Send a message to the chatbot\n",
    "Now, you can send a message to the chatbot and receive a response. In this example, we will ask the chatbot a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call OpenAI API...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " What is the capital of France?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The capital of France is Paris."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "message = \"What is the capital of France?\"\n",
    "response = chat_instance.reply(message)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using MemoryIndex with the Chat class\n",
    "You can use MemoryIndex with the Chat class to handle queries and store relevant information. First, let's import the necessary modules and create a MemoryIndex instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "memory_index = MemoryIndex()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, add some key-value pairs to the memory index. In this example, we will add information about the capitals of a few countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_index.add_to_index(\"What is the capital of France? The capital of France is Paris.\")\n",
    "memory_index.add_to_index(\"What is the capital of Germany? The capital of Germany is Berlin.\")\n",
    "memory_index.add_to_index(\"What is the capital of Italy? The capital of Italy is Rome.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a new instance of the Chat class and set the index_dict parameter to include the MemoryIndex instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_instance_with_index = Chat(model=\"gpt-3.5-turbo\", index_dict={\"capitals\": memory_index})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the current index for the chatbot to use when providing hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_instance_with_index.set_current_index(\"capitals\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, send a message to the chatbot using the MemoryIndex instance for hints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"What is the capital of France?\"\n",
    "response = chat_instance_with_index.reply(message)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
