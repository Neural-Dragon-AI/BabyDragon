{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable, List, Optional\n",
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "from babydragon.memory.kernels.memory_kernel import MemoryKernel\n",
    "from babydragon.memory.indexes.python_index import PythonIndex\n",
    "from babydragon.chat.memory_chat import FifoChat\n",
    "import babydragon\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babydragon_path = os.path.dirname(os.path.abspath(babydragon.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex= PythonIndex(babydragon_path, name=\"babyd_index_parallel\", minify_code=False, load = True, max_workers=16, backup= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babykernel = MemoryKernel(babyindex, name=\"babyd_kernel_parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = FifoChat(model= \"gpt-3.5-turbo\", index_dict = {\"babyindex\":babyindex}, name=\"babyd_chatbot\", max_fifo_memory=1500, max_index_memory = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.reply(\"What is a MemoryThread?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babydragon.tasks.llm_task import LLMReader, LLMWriter\n",
    "from babydragon.chat.chat import Chat\n",
    "\n",
    "system_prompt = \"You are a helfpul summarizer. The user will input some code from the babydragon package, you have to write a summary of what the code does for future documentation use.\\n\\n\"\n",
    "\n",
    "\n",
    "def summary_prompt(paragraph):\n",
    "    return f\"Summarize the following paragraph:\\n\\n{paragraph}\\n\\nSummary:\"\n",
    "\n",
    "\n",
    "summarizer = Chat(system_prompt=system_prompt, user_prompt=summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = babykernel\n",
    "path = [[x] for x in range(len(target_index.values))]\n",
    "# path = [list(range(len(target_index.values)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_task = LLMWriter(\n",
    "    index=target_index,\n",
    "    path=path,\n",
    "    chatbot=summarizer,\n",
    "    max_workers=8,\n",
    "    task_id=\"summary_kernel_16\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_index = summary_task.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Error in sub-task 75: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bed63f4e74f83287e976399fa1b767dc in your message.)',\n",
       "  'Error in sub-task 102: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 372a0c49dfa9ffac5896696283479088 in your message.)',\n",
       "  'The code defines a class called OpenAiEmbedder that has methods to get the size of embeddings and to generate embeddings based on input data. The embed method takes in data as input and uses the OpenAI API to create embeddings. It has the option to embed data with or without preprocessing and can print out information to the console if verbose mode is enabled. The output is a single embedding vector.',\n",
       "  \"The code is from the babydragon package and contains classes and methods for creating chatbots using OpenAI's ChatCompletion API. The Prompter class handles system and user prompts and can be subclassed to change how prompts are composed. The BaseChat class provides basic functions for chatting with the API and a Gradio interface for the chatbot. It also includes methods for querying and resetting the chatbot's memory. The code includes helper functions for working with API responses and encoding messages for the API.\",\n",
       "  \"The code defines an embedding function that takes input data and optionally adds a mark, and then uses OpenAI's text-embedding-ada-002 engine to create an embedding of the input. The function can also take a verbose flag for logging purposes, and returns the embedding of the input data.\",\n",
       "  'This is a collection of helper functions for use with the openai package. The functions are used to mark messages as being from a system, assistant, or user. There is also a function to check if a message dictionary is valid, and two functions to extract the message content from a response either as a dictionary or a string.',\n",
       "  'The code defines a function that takes a string as input and uses the libcst library to parse it into a module. It then finds all the functions in the module and embeds them separately using the OpenAI language model. The resulting embeddings are averaged and returned as a list of numpy arrays.',\n",
       "  'The code imports necessary packages, sets constants for embedding and context length, defines a class for OpenAI embedding and a function for averaging embeddings. The `embed` function uses the OpenAI API to embed text data using the Ada engine. The `parse_and_embed_functions` function uses the `libcst` package to parse a string of code, retrieves all functions and classes, embeds them separately, and returns the average embedding of all the functions.',\n",
       "  'The code defines several prompts and messages for a chatbot assistant that can use an external knowledge base to answer questions. The system prompt explains how the chatbot works, while the index hint prompt informs the user of the hints that will be used to answer the question. The code uses placeholders to allow for variable inputs such as the index description and the actual question being asked.',\n",
       "  'This code creates a Gradio interface for a chatbot and launches it. The interface allows the user to input text or upload an image, and includes a textbox and a button to clear the screen. The function also includes a submission command to execute a text response by the chatbot using the entered text.'],\n",
       " [0.7986195,\n",
       "  0.79690075,\n",
       "  0.7959765,\n",
       "  0.78815025,\n",
       "  0.78722054,\n",
       "  0.78063333,\n",
       "  0.7699576,\n",
       "  0.76508725,\n",
       "  0.76367795,\n",
       "  0.7589431],\n",
       " array([[ 75, 102, 306,  17, 133, 266, 134, 136,  35,  16]], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_index.faiss_query(\"OpenAI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
