{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danielhug/neuraldragon/gitensor/BabyDragon/babydragon\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/danielhug/neuraldragon/.venv/lib/python3.10/site-packages')\n",
    "sys.path.append(\"/Users/danielhug/neuraldragon/gitensor/BabyDragon\")\n",
    "\n",
    "import os\n",
    "import babydragon\n",
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "from babydragon.memory.indexes.python_index import PythonIndex\n",
    "from babydragon.memory.kernels.memory_kernel import MemoryKernel\n",
    "from babydragon.chat.chat import Chat\n",
    "import openai\n",
    "from babydragon.models.embedders.cohere import CohereEmbedder\n",
    "from babydragon.models.embedders.ada2 import OpenAiEmbedder\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "openai.api_key =  \"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\"\n",
    "\n",
    "babydragon_path = os.path.dirname(os.path.abspath(babydragon.__file__))\n",
    "print(babydragon_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class SubjectPerspectiveAnalyzer:\n",
    "    def __init__(self, chatbot: Chat):\n",
    "        self.chatbot = chatbot\n",
    "\n",
    "    def analyze_subject_perspective(self, user_subject: str, user_perspective: str) -> dict:\n",
    "        prompts = [\n",
    "            f\"Generate ideas and concepts that explore the connection between {user_subject} and {user_perspective}, considering both traditional and unconventional approaches.\",\n",
    "            f\"List key concepts or topics that would help analyze {user_subject} through the lens of {user_perspective}, including relevant principles, theories, or models.\",\n",
    "            f\"Identify potential areas or research topics where {user_subject} and {user_perspective} intersect, highlighting intriguing or innovative perspectives.\"\n",
    "        ]\n",
    "\n",
    "        output = {}\n",
    "        for prompt in prompts:\n",
    "            response = self.chatbot.reply(prompt)\n",
    "            output[prompt] = self._format_response(response)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _format_response(self, response: str) -> list:\n",
    "        formatted_response = response.strip().split('\\n')\n",
    "        return formatted_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Ideation:\n",
    "    def __init__(self, memory_index: MemoryIndex):\n",
    "        self.memory_index = memory_index\n",
    "\n",
    "    def retrieve_ideas(self, queries: Dict, k: int = 30, max_tokens: int = 10000):\n",
    "        \"\"\"\n",
    "        Generate ideas based on the given list of queries.\n",
    "\n",
    "        Args:\n",
    "            queries: The list of queries for generating ideas.\n",
    "            k: The number of top search results to consider.\n",
    "            max_tokens: The maximum number of tokens to return.\n",
    "\n",
    "        Returns:\n",
    "            A list of ideas generated based on the queries.\n",
    "        \"\"\"\n",
    "        ideas = []\n",
    "        for key, queries in queries.items():\n",
    "            for query in queries:\n",
    "                if query is None or len(query) < 10:\n",
    "                    continue\n",
    "                top_k_hints, scores, indices = self.memory_index.token_bound_query(\n",
    "                    query, k=k, max_tokens=max_tokens\n",
    "                )\n",
    "                last_query = self.memory_index.query_history[-1]\n",
    "                hints_tokens = last_query[\"hints_tokens\"]\n",
    "                returned_tokens = last_query[\"returned_tokens\"]\n",
    "\n",
    "                ideas.append({\"key_task\": key, \"query\": query, \"hints\": top_k_hints, \"scores\": scores, \"hints_tokens\": hints_tokens, \"returned_tokens\": returned_tokens})\n",
    "\n",
    "        return ideas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call OpenAI API...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " Generate ideas and concepts that explore the connection between AI in Healthcare and Ethical Considerations, considering both traditional and unconventional approaches."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " Here are some ideas and concepts on the connection between AI in Healthcare and Ethical Considerations:\n",
       "\n",
       "1. Transparency: There is an ethical concern about how healthcare providers use AI technology, including issues such as how to ensure transparency in how AI algorithms make decisions. One concept to address this concern involves developing new policies requiring AI developers and operators to provide transparency in their algorithms, allowing healthcare providers and patients to see how and why the AI made certain decisions.\n",
       "\n",
       "2. Bias: Another ethical consideration is the absence of bias in AI technology, as unfair treatment can have negative consequences on the quality of care. An idea to address this issue is to develop algorithms that can identify and correct bias in data, ensuring that patients from all backgrounds receive equal and accurate treatment.\n",
       "\n",
       "3. Privacy: With data protection becoming a growing concern, AI technology includes several ethical considerations around data privacy. One concept to consider is to ensure that AI algorithms only access the minimum amount of personal information that is essential to the health condition at hand. This reduces the risks of data breaches and unnecessary access to patients' sensitive information.\n",
       "\n",
       "4. Autonomous decision-making: The use of AI in healthcare also raises the question of who is responsible when an AI system makes a mistake. One concept involves designing an autonomous decision-making model that is supervised by healthcare professionals to ensure the AI acts within ethical boundaries and accountable for its actions.\n",
       "\n",
       "5. Informed Consent: AI decision-making raises concerns about the role of patients in the decision-making process. One approach is to assure that every patient receives sufficient and understandable information before any AI-driven decision, to encourage an informed consent culture.\n",
       "\n",
       "6. End-of-life decisions: While healthcare professionals use AI to make treatment decisions, ethical considerations surround patients nearing the end of life, especially with decisions involving comfort or life-support. An innovative concept is to use AI to facilitate ethical conversations between healthcare providers and patients or their family members about end-of-life care, from which providers can make a more personalized decision.\n",
       "\n",
       "7. Mental Health: AI technologies can provide healthcare solutions that shift towards patient wellness as opposed to the illness, where ethical considerations such as privacy and consent need to be considered. A possible concept to address such issues would be to ensure that patients are aware of their AI-powered diagnosis, including the data captured and how it influenced such decisions.\n",
       "\n",
       "These are only a few ideas and concepts and not an exhaustive list. It is important to note that ethical considerations encompass a wide range of issues associated with AI in healthcare, and there is a need for the healthcare industry to keep working on developing solutions that consider patients' well-being and Data protection."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call OpenAI API...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " List key concepts or topics that would help analyze AI in Healthcare through the lens of Ethical Considerations, including relevant principles, theories, or models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " Analyzing AI in healthcare through the lens of ethical considerations requires an understanding of various key concepts or topics. Some of these concepts are:\n",
       "\n",
       "1. Beneficence: This principle focuses on the need for AI in healthcare to promote good and provide benefit to patients. It lays emphasis on the duty of healthcare practitioners to act in the best interest of patients.\n",
       "\n",
       "2. Non-maleficence: This principle ensures that AI systems should not result in harm to patients. It emphasizes the need for stringent guidelines and regulations to prevent potential harm.\n",
       "\n",
       "3. Autonomy: This principle emphasizes the need for patients to have control over their treatment decisions, which includes their ability to provide informed consent to AI interventions.\n",
       "\n",
       "4. Fairness: This concept ha to do with issues of bias and equity in AI healthcare, and requires that all patients are treated equally in terms of access to AI healthcare.\n",
       "\n",
       "5. Transparency: The ethical use of AI in healthcare requires that stakeholders have access to the algorithms used by these systems and adequate explanations of how decisions were made.\n",
       "\n",
       "6. Accountability: This requires developers, providers, and users of AI healthcare to be held responsible for the consequences of its use.\n",
       "\n",
       "7. Privacy and Confidentiality: AI in healthcare requires sensitive patient information to be stored and used appropriately through privacy and security controls.\n",
       "\n",
       "8. Explainability: This concept requires that AI systems can provide information about its decision-making process in a way that stakeholders can understand.\n",
       "\n",
       "Overall, an ethical analysis of AI in healthcare requires a careful consideration of these ethical principles and concepts, as well as applicable legal, regulatory, and socio-economic factors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call OpenAI API...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " Identify potential areas or research topics where AI in Healthcare and Ethical Considerations intersect, highlighting intriguing or innovative perspectives."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " There are several potential areas of research where AI in Healthcare and Ethical Considerations intersect. Below are some of the most interesting and innovative ones:\n",
       "\n",
       "1. Fairness and Bias: One of the most pressing ethical issues in AI in healthcare is that of algorithmic bias. Research into how algorithms and machine learning models can be fairer and more balanced in their predictions is essential in ensuring that AI systems do not perpetuate existing biases, prejudices, or health disparities in society.\n",
       "\n",
       "2. Privacy and Data Sharing: Another area of ethical concern is how AI systems handle sensitive health data. Research into how to ensure patient privacy, confidentiality, and data security is essential in fostering trust in AI-powered healthcare systems.\n",
       "\n",
       "3. Informed Consent: AI systems have the ability to make decisions that could significantly affect patients' lives. Research into how to ensure that patients are informed about the use of AI in their healthcare and are given the opportunity to make informed decisions about their care is crucial.\n",
       "\n",
       "4. Human-Machine Interaction: As AI systems become more integrated into healthcare delivery, there is a need for research into how to promote effective communication and collaboration between human clinicians and AI-powered systems. Studies could examine the impact of AI systems on patient-clinician relationships, as well as how to design interfaces that are intuitive and easy to use.\n",
       "\n",
       "5. Clinical Decision-making: Finally, the implementation of AI in clinical decision-making raises important ethical considerations. Research into how to ensure that AI models are transparent, explainable, and accountable can help clinicians make more informed decisions and avoid potential harms to patients. Moreover, ethical perspectives in designing AI models for clinical decision making need to be examined.\n",
       "\n",
       "Overall, these research areas and topics are highly relevant to the development, implementation, and evaluation of AI in healthcare, and should be pursued to ensure that these systems can be optimized for patient well-being in ways that is ethical, accurate, and fair."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Chat instance\n",
    "chat_instance = Chat(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define user input\n",
    "user_subject = \"AI in Healthcare\"\n",
    "user_perspective = \"Ethical Considerations\"\n",
    "\n",
    "# Create a SubjectPerspectiveAnalyzer instance and analyze input\n",
    "analyzer = SubjectPerspectiveAnalyzer(chat_instance)\n",
    "output = analyzer.analyze_subject_perspective(user_subject, user_perspective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/danielhug/.cache/huggingface/datasets/Cohere___parquet/Cohere--wikipedia-22-12-simple-embeddings-94deea3d55a22093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging values: Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/danielhug/.cache/huggingface/datasets/Cohere___parquet/Cohere--wikipedia-22-12-simple-embeddings-94deea3d55a22093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-a67d988b71456881.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging values: Done\n",
      "Creating a new index from a list of embeddings and values\n",
      "Adding batched embeddings to index\n",
      "<class 'list'>\n",
      "485859  values in the index\n",
      "485859  embeddings in the index\n",
      "Time to index:  1154.4764938970002\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "dataset_url = \"Cohere/wikipedia-22-12-simple-embeddings\"\n",
    "start = perf_counter()\n",
    "index = MemoryIndex.from_hf_dataset(dataset_url, [\"title\", \"text\"], \"emb\", name=\"wikipedia\", is_batched=True)\n",
    "end = perf_counter()\n",
    "print(\"Time to index: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from storage/wikipedia\n"
     ]
    }
   ],
   "source": [
    "memory_index = MemoryIndex(name=\"wikipedia\", load=True, max_workers=8, embedder=CohereEmbedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideation = Ideation(memory_index=memory_index)\n",
    "ideas = ideation.retrieve_ideas(output, k=40, max_tokens=10000)\n",
    "gathered_docs = []\n",
    "token_count = 0\n",
    "for idea in ideas:\n",
    "    token_count += idea[\"returned_tokens\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hdbscan\n",
    "import umap\n",
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "class IdeaCluster:\n",
    "    def __init__(self, ideas: list, max_tokens_per_cluster: int):\n",
    "        self.ideas = ideas\n",
    "        self.max_tokens_per_cluster = max_tokens_per_cluster\n",
    "        self.idea_index = self.create_idea_index()\n",
    "        self.cluster_labels = None\n",
    "\n",
    "    def create_idea_index(self):\n",
    "        gathered_docs = []\n",
    "        for idea in self.ideas:\n",
    "            for hint, score in zip(idea[\"hints\"], idea[\"scores\"]):\n",
    "                gathered_docs.append(hint)\n",
    "        idea_index = MemoryIndex(values=gathered_docs, is_batched=True, name=\"ideas\")\n",
    "        return idea_index\n",
    "\n",
    "    def cluster_embeddings(self, n_neighbors: int = 10, min_cluster_size: int = 5):\n",
    "        reducer = umap.UMAP(n_neighbors=n_neighbors)\n",
    "        reduced_embeddings = reducer.fit_transform(self.idea_index.embeddings)\n",
    "\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "        labels = clusterer.fit_predict(reduced_embeddings)\n",
    "\n",
    "        token_count_per_cluster = self.count_tokens_per_cluster(labels)\n",
    "        print(token_count_per_cluster)\n",
    "        if max(token_count_per_cluster.values()) <= self.max_tokens_per_cluster:\n",
    "            self.cluster_labels = labels\n",
    "            print(\"Clusters created successfully.\")\n",
    "        else:\n",
    "            print(\"Clusters exceed the maximum token count.\")\n",
    "\n",
    "    def count_tokens_per_cluster(self, labels):\n",
    "        token_count_per_cluster = {}\n",
    "        for label, hint in zip(labels, self.ideas):\n",
    "            tokens = hint[\"returned_tokens\"]\n",
    "            if label not in token_count_per_cluster:\n",
    "                token_count_per_cluster[label] = tokens\n",
    "            else:\n",
    "                token_count_per_cluster[label] += tokens\n",
    "        return token_count_per_cluster\n",
    "\n",
    "    def create_minimum_spanning_paths(self):\n",
    "        if self.cluster_labels is None:\n",
    "            raise ValueError(\"You must run cluster_embeddings() before creating minimum spanning paths.\")\n",
    "\n",
    "        unique_labels = np.unique(self.cluster_labels)\n",
    "        min_span_paths = []\n",
    "\n",
    "        for label in unique_labels:\n",
    "            if label == -1:  # Skip the noise cluster\n",
    "                continue\n",
    "\n",
    "            # Get the indices of the current cluster\n",
    "            cluster_indices = np.where(self.cluster_labels == label)[0]\n",
    "\n",
    "            # Calculate the pairwise distances between embeddings in the cluster\n",
    "            cluster_embeddings = self.idea_index.embeddings[cluster_indices]\n",
    "            dist_matrix = squareform(pdist(cluster_embeddings))\n",
    "\n",
    "            # Create a graph from the distance matrix\n",
    "            graph = nx.from_numpy_array(dist_matrix)\n",
    "\n",
    "            # Compute the minimum spanning tree of the graph\n",
    "            min_span_tree = nx.minimum_spanning_tree(graph)\n",
    "\n",
    "            # Get the minimum spanning paths\n",
    "            min_span_path = nx.shortest_path(min_span_tree)\n",
    "\n",
    "            # Convert node indices to indices in the original memory index\n",
    "            cluster_paths = []\n",
    "            for key, path in min_span_path.items():\n",
    "                orig_key = cluster_indices[key]\n",
    "                orig_path = [cluster_indices[node] for node in path]\n",
    "                cluster_paths.append(orig_path)\n",
    "\n",
    "            min_span_paths.append(cluster_paths)\n",
    "\n",
    "        self.min_span_paths = min_span_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new index from a list of values\n",
      "Embedding batch 0 took  3.143320083618164  seconds\n",
      "Batch 0 of 1\n",
      "1040  values in the index\n",
      "1040  embeddings in the index\n",
      "{7: 3116, 8: 3390, 2: 3155, 39: 6774, 5: 3259, 0: 3025, 21: 3887, 34: 3635, 18: 3059, 35: 8758, 13: 3255, 45: 3106, 24: 3500, 22: 3720, 28: 6814, 30: 2710, 16: 2753, 37: 2998, 40: 3034, 33: 3482, 67: 3551, 11: 2966}\n",
      "Clusters created successfully.\n"
     ]
    }
   ],
   "source": [
    "max_tokens_per_cluster = 10000\n",
    "idea_cluster = IdeaCluster(ideas, max_tokens_per_cluster)\n",
    "idea_cluster.cluster_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_cluster.create_minimum_spanning_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up savepath\n",
      "Executing task LLMWriteTask using 1 workers.\n",
      "RateLimiter: This is the first call, no wait required.\n",
      "Trying to call OpenAI API...\n",
      "Keyboard interrupt detected, stopping task execution.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " Artificial intelligenceBorrowing from the management literature, Kaplan and Haenlein classify artificial intelligence into three different types of AI systems: analytical, human-inspired, and humanized artificial intelligence. Analytical AI has only characteristics consistent with cognitive intelligence generating cognitive representation of the world and using learning based on past experience to inform future decisions. Human-inspired AI has elements from cognitive as well as emotional intelligence, understanding, in addition to cognitive elements, also human emotions considering them in their decision making. Humanized AI shows characteristics of all types of competencies (i.e., cognitive, emotional, and social intelligence), able to be self-conscious and self-aware in interactions with others."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " Analytical AI:\n",
       "Analytical AI systems are focused on cognitive intelligence and are designed to process and analyze data to make decisions based on past experiences. These systems use different techniques like machine learning, data mining, and statistical analysis to identify patterns in data and generate insights. Some applications of analytical AI include fraud detection, customer segmentation, demand forecasting, and predictive maintenance.\n",
       "\n",
       "Human-inspired AI:\n",
       "Human-inspired AI systems integrate elements of both cognitive and emotional intelligence. They aim to understand human emotions and exhibit empathy in their interactions. These systems use natural language processing, sentiment analysis, and emotion recognition technologies to interpret emotions and adjust their responses accordingly. Examples of human-inspired AI include chatbots, virtual assistants, and AI-driven customer support systems that can communicate with users in a more human-like and emotionally engaging manner.\n",
       "\n",
       "Humanized AI:\n",
       "Humanized AI systems are the most advanced form of AI, incorporating cognitive, emotional, and social intelligence. These systems have a high level of self-awareness and self-consciousness, enabling them to adapt their behavior according to specific situations and interactions with humans. Humanized AI can understand complex human emotions, exhibit empathy, and engage in meaningful, context-aware communication. These systems can also learn from both explicit and implicit inputs, allowing them to improve their performance over time. Applications of humanized AI are still in the early stages of development but might include highly advanced personal assistants, AI-driven healthcare providers, and various forms of human-AI collaboration across numerous industries.\n",
       "\n",
       "In summary, the three types of AI systems, analytical, human-inspired, and humanized AI, differ in the level of intelligence they exhibit and the kind of interactions they have with humans. While analytical AI deals primarily with cognitive intelligence, human-inspired AI incorporates emotional intelligence, and humanized AI includes cognitive, emotional, and social intelligence. These three types of AI systems have varying applications and continue to evolve as technology advances."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call OpenAI API...\n"
     ]
    }
   ],
   "source": [
    "from babydragon.tasks.llm_task import LLMWriter\n",
    "chatbot = Chat(model=\"gpt-4\")\n",
    "\n",
    "# Iterate over the minimum spanning paths and generate summaries\n",
    "all_summaries = []\n",
    "for cluster_paths in idea_cluster.min_span_paths:\n",
    "    cluster_summaries = []\n",
    "    for path in cluster_paths:\n",
    "        llm_writer = LLMWriter(\n",
    "            index=idea_cluster.idea_index,\n",
    "            path=[path],\n",
    "            chatbot=chatbot,\n",
    "            task_name=\"summary\",\n",
    "            max_workers=1,\n",
    "            backup=False,\n",
    "        )\n",
    "        summary_index = llm_writer.write()\n",
    "        cluster_summaries.append(summary_index.values)\n",
    "    all_summaries.append(cluster_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
