{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyDragon Indexes\n",
    "\n",
    "The `indexes` submodule of the BabyDragon package provides different indexing\n",
    "and searching strategies for various data types.\n",
    "The main class in this\n",
    "submodule is  `MemoryIndex` class, a wrapper for a Faiss index that simplifies managing the index and associated data. It supports creating an index from scratch, loading an index from a file, or initializing from a pandas DataFrame. The class also provides methods for adding and removing items from the index, querying the index, saving and loading the index, and pruning the index based on certain constraints.\n",
    "\n",
    "##  Table of Contents\n",
    "\n",
    "1. [MemoryIndex](#usage)\n",
    "   - [Initializing a MemoryIndex](#initializing-a-memoryindex)\n",
    "   - [Adding and Removing Items](#adding-and-removing-items)\n",
    "   - [Querying the Index](#querying-the-index)\n",
    "   - [Saving and Loading](#saving-and-loading)\n",
    "   - [Pruning the Index](#pruning-the-index)\n",
    "   - [Multithreading](#multithreading)\n",
    "2. [Examples](#examples)\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Initializing a MemoryIndex\n",
    "\n",
    "A `MemoryIndex` object can be initialized in several ways:\n",
    "1. Create a new empty index from scratch:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new index\n"
     ]
    }
   ],
   "source": [
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "\n",
    "index = MemoryIndex()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before adding values we need to specify an api key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a new index from a list of values using the default ada02 embedder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new index from a list of values\n",
      "Embedding value  0  of  3\n",
      "Embedding value  0  took  0.21761608123779297  seconds\n",
      "Embedding value  1  of  3\n",
      "Embedding value  1  took  0.7341010570526123  seconds\n",
      "Embedding value  2  of  3\n",
      "Embedding value  2  took  0.20077300071716309  seconds\n"
     ]
    }
   ],
   "source": [
    "values = [\"apple\", \"banana\", \"cherry\"]\n",
    "\n",
    "index = MemoryIndex(values=values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now search the index using the underlying faiss index by calling the `faiss_query` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 0.9999985\n",
      "banana 0.90329254\n",
      "cherry 0.8461201\n"
     ]
    }
   ],
   "source": [
    "results, scores, indeces = index.faiss_query(\"apple\", k=3)\n",
    "for result, score in zip(results, scores):\n",
    "    print(result, score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a new index from a list of values and their embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new index from a list of embeddings and values\n",
      "apple 0.9999985\n",
      "banana 0.90340185\n",
      "cherry 0.84610236\n"
     ]
    }
   ],
   "source": [
    "from babydragon.models.embedders.ada2 import OpenAiEmbedder\n",
    "embedder = OpenAiEmbedder()\n",
    "\n",
    "embeddings = []\n",
    "for value in values:\n",
    "    embeddings.append(embedder.embed(value))\n",
    "\n",
    "index = MemoryIndex(name=\"precomputed_index\",values=values, embeddings=embeddings)\n",
    "\n",
    "results, scores, indeces = index.faiss_query(\"apple\", k=3)\n",
    "for result, score in zip(results, scores):\n",
    "    print(result, score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Load an existing index from a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from storage/precomputed_index\n"
     ]
    }
   ],
   "source": [
    "index = MemoryIndex(load=True, name = \"precomputed_index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Initialize a MemoryIndex object from a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the DataFrame\n",
      "Creating a new index from a list of embeddings and values\n",
      "apple 0.9999981\n",
      "banana 0.90342164\n",
      "cherry 0.8461188\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_frame = pd.DataFrame({\n",
    "    \"values\": values,\n",
    "    \"embeddings\": embeddings  # list of embeddings corresponding to the values\n",
    "})\n",
    "\n",
    "index = MemoryIndex.from_pandas(data_frame=data_frame, columns=\"values\", embeddings_col=\"embeddings\")\n",
    "\n",
    "results, scores, indeces = index.faiss_query(\"apple\", k=3)\n",
    "for result, score in zip(results, scores):\n",
    "    print(result, score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Adding and Removing Items\n",
    "You can add items to the index by calling the add_to_index method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 0.9999981\n",
      "banana 0.90342164\n",
      "orange 0.86520016\n",
      "cherry 0.8461188\n"
     ]
    }
   ],
   "source": [
    "index.add_to_index(value=\"orange\")\n",
    "\n",
    "results, scores, indeces = index.faiss_query(\"apple\", k=4)\n",
    "for result, score in zip(results, scores):\n",
    "    print(result, score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also remove items from the index by calling the remove_from_index method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 0.9999981\n",
      "orange 0.86520016\n",
      "cherry 0.8461188\n"
     ]
    }
   ],
   "source": [
    "index.remove_from_index(value=\"banana\")\n",
    "\n",
    "results, scores, indeces = index.faiss_query(\"apple\", k=4)\n",
    "for result, score in zip(results, scores):\n",
    "    print(result, score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the Index\n",
    "To query the index, use the faiss_query or token_bound_query methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 0.9044406\n",
      "orange 0.8771416\n",
      "cherry 0.860623\n"
     ]
    }
   ],
   "source": [
    "# Query the top-5 most similar values with a maximum tokens constraint\n",
    "\n",
    "results, scores, indices = index.token_bound_query(query=\"fruit\", k=5, max_tokens=4)\n",
    "for result, score in zip(results, scores):\n",
    "    print(result, score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading\n",
    "After modifying the index you can save the index to disk by calling the save method, the location and name of the file is controlled by the `index.save_path` and `index.name` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.name=\"precomputed_index\"\n",
    "index.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load an index from a file by calling the load method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from storage/precomputed_index\n"
     ]
    }
   ],
   "source": [
    "index = MemoryIndex(load=True, name= \"precomputed_index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning the Index\n",
    "To prune the index based on certain constraints, use the prune method. If you want to prune the index based on the number of tokens for each value you can define the pruning method as lenght and give an inclusive length constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning by length\n",
      "Length constraint:  (0, 1)\n",
      "Number of values:  3\n",
      "tokenizer:  <Encoding 'cl100k_base'>\n",
      "value apple is in range (0, 1)\n",
      "value banana is in range (0, 1)\n",
      "Creating a new index from a list of embeddings and values\n",
      "banana 0.9200244\n",
      "apple 0.9044848\n"
     ]
    }
   ],
   "source": [
    "pruned_index=index.prune(\"length\",length_constraint=(0,1))\n",
    "results, scores, indices = pruned_index.token_bound_query(query=\"fruit\", k=5, max_tokens=4)\n",
    "for result, score in zip(results, scores):\n",
    "    print(result, score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use a regular expression that must be matched for the index to be included, in the example we filter out apple with the regex \"^(?!.*apple).*$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new index from a list of embeddings and values\n",
      "banana 0.9199276\n",
      "cherry 0.860623\n"
     ]
    }
   ],
   "source": [
    "pruned_index=index.prune(\"regex\",regex_pattern=\"^(?!.*apple).*$\")\n",
    "# write the regex pattern for searching not apple\n",
    "results, scores, indices = pruned_index.token_bound_query(query=\"fruit\", k=5, max_tokens=4)\n",
    "for result, score in zip(results, scores):\n",
    "    print(result, score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading\n",
    "In order to enable multi-threading for speeding up the embedding process, you can set the `max_workers parameter to a value bigger than 1, the current rate limits parameters are conservative to avoid open_ai errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 3 values\n",
      "setting up savepath\n",
      "Executing task memory_index_embedding_task using 8 workers.\n",
      "RateLimiter: This is the first call, no wait required.\n",
      "RateLimiter: Waiting for 0.04 seconds before next call.\n",
      "RateLimiter: Waiting for 0.04 seconds before next call.\n",
      "Sub-task 0 executed in 0.21 seconds.\n",
      "Sub-task 0 results saved in 0.00 seconds.\n",
      "Sub-task 1 executed in 0.17 seconds.\n",
      "Sub-task 1 results saved in 0.00 seconds.\n",
      "Sub-task 2 executed in 0.05 seconds.\n",
      "Sub-task 2 results saved in 0.00 seconds.\n",
      "Task execution completed.\n",
      "Creating a new index from a list of embeddings and values\n"
     ]
    }
   ],
   "source": [
    "index = MemoryIndex(values=values,max_workers=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
