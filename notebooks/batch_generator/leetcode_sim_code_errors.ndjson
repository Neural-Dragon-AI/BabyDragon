{"error": {"message": "This model's maximum context length is 16385 tokens. However, you requested 17419 tokens (13419 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 16385 tokens. However, you requested 18561 tokens (14561 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
{"error": {"message": "This model's maximum context length is 16385 tokens. However, your messages resulted in 41698 tokens. Please reduce the length of the messages.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}
