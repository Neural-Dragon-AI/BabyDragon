{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading metadata: 100%|██████████| 1.29k/1.29k [00:00<00:00, 1.06MB/s]\n",
      "Downloading readme: 100%|██████████| 3.84k/3.84k [00:00<00:00, 2.43MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikipedia-22-12-embeddings/simple (download: 1.52 GiB, generated: 1.57 GiB, post-processed: Unknown size, total: 3.09 GiB) to /Users/iridella/.cache/huggingface/datasets/Cohere___parquet/Cohere--wikipedia-22-12-simple-embeddings-94deea3d55a22093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 409M/409M [00:12<00:00, 33.2MB/s]\n",
      "Downloading data: 100%|██████████| 408M/408M [00:16<00:00, 24.9MB/s]\n",
      "Downloading data: 100%|██████████| 407M/407M [00:12<00:00, 33.5MB/s]\n",
      "Downloading data: 100%|██████████| 404M/404M [00:11<00:00, 35.4MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:56<00:00, 56.83s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 262.60it/s]\n",
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /Users/iridella/.cache/huggingface/datasets/Cohere___parquet/Cohere--wikipedia-22-12-simple-embeddings-94deea3d55a22093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "docs = load_dataset(f\"Cohere/wikipedia-22-12-simple-embeddings\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    }
   ],
   "source": [
    "docs.save_to_disk(r\"/Users/iridella/Documents/BabyDragon/notebooks/storage/\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Custom Subclasses for Chat and Prompter Classes: FifoChat, VectorChat, and FifoVectorChat\n",
    "In this tutorial, we will demonstrate how to use custom subclasses for the Chat and Prompter classes in the BabyDragon chatbot framework. These subclasses are FifoChat, VectorChat, and FifoVectorChat. These classes allow you to create a chatbot with different memory management strategies, such as first-in-first-out (FIFO) memory, vector memory, or a combination of both.\n",
    "\n",
    "### 1. Import necessary modules\n",
    "Before we begin, let's import the necessary modules."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Chatbot with different memory strategies\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 FifoChat\n",
    "FifoChat is a chatbot subclass that utilizes a first-in-first-out (FIFO) memory strategy. When the memory limit is reached, the oldest messages are removed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifo_chatbot = FifoChat(model=\"gpt-4.5-turbo\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 VectorChat\n",
    "VectorChat is a chatbot subclass that uses a vector memory strategy. The memory prompt is constructed by filling the memory with the k most similar messages to the question until the maximum prompt memory tokens are reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_chatbot = VectorChat(model=\"gpt-4.5-turbo\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 FifoVectorChat\n",
    "FifoVectorChat is a chatbot subclass that combines both FIFO and vector memory strategies. The memory prompt is constructed by including both FIFO memory and vector memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifo_vector_chatbot = FifoVectorChat(model=\"gpt-4.5-turbo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
