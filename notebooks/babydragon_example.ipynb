{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable, List, Optional\n",
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "from babydragon.memory.kernels.memory_kernel import MemoryKernel\n",
    "from babydragon.memory.indexes.python_index import PythonIndex\n",
    "from babydragon.chat.memory_chat import FifoChat\n",
    "from babydragon.chat.chat import Chat\n",
    "import babydragon\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babydragon_path = os.path.dirname(os.path.abspath(babydragon.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex= PythonIndex(babydragon_path, name=\"babyd_index_parallel\", minify_code=False, load = True, max_workers=16, backup= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = FifoChat(model= \"gpt-3.5-turbo\", index_dict = {\"babyindex\":babyindex}, name=\"babyd_chatbot\", max_index_memory = 2500, max_output_tokens= 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chatbot.user_prompt)\n",
    "print(chatbot.user_defined_user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.current_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.set_current_index(None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.reply(\"What is a memoryindex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex.faiss_query(\"open ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babykernel = MemoryKernel(babyindex, name=\"babyd_kernel_parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = FifoChat(model= \"gpt-3.5-turbo\", index_dict = {\"babyindex\":babyindex}, name=\"babyd_chatbot\", max_fifo_memory=1000, max_index_memory = 2500, max_output_tokens= 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.reply(\"What is a MemoryThread?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babydragon.tasks.llm_task import LLMReader, LLMWriter\n",
    "from babydragon.chat.chat import Chat\n",
    "\n",
    "system_prompt = \"You are a helfpul summarizer. The user will input some code from the babydragon package, you have to write a summary of what the code does for future documentation use.\\n\\n\"\n",
    "\n",
    "\n",
    "def summary_prompt(paragraph):\n",
    "    return f\"Summarize the following paragraph:\\n\\n{paragraph}\\n\\nSummary:\"\n",
    "\n",
    "\n",
    "summarizer = Chat(system_prompt=system_prompt, user_prompt=summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = babyindex\n",
    "path = [[x] for x in range(len(target_index.values))]\n",
    "# path = [list(range(len(target_index.values)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_task = LLMWriter(\n",
    "    index=target_index,\n",
    "    path=path,\n",
    "    chatbot=summarizer,\n",
    "    max_workers=12,\n",
    "    task_id=\"summary_babydragon\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex_summary = summary_task.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babyindex_summary.faiss_query(\"OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_summary = FifoChat(model= \"gpt-3.5-turbo\", index_dict = {\"babyindex_summary\":babyindex_summary}, name=\"babyd_chatbot_summary\", max_fifo_memory=1000, max_index_memory = 2500, max_output_tokens= 400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
