{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable, List, Optional\n",
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "from babydragon.memory.indexes.python_index import PythonIndex\n",
    "from babydragon.chat.memory_chat import FifoChat\n",
    "import babydragon\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "babydragon_path = os.path.dirname(os.path.abspath(babydragon.__file__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new index\n",
      "Indexing 309 functions and 48 classes\n"
     ]
    }
   ],
   "source": [
    "babyindex= PythonIndex(babydragon_path, name=\"babyd_index\", minify_code=False, load = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = FifoChat(model= \"gpt-4\", index_dict = {\"babyindex\":babyindex}, name=\"babyd_chatbot\", max_fifo_memory=2500, max_index_memory = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['\\n\\nclass PythonIndex(MemoryIndex, PythonParser):\\n    def __init__(\\n        self,\\n        directory_path: str,\\n        name: str = \"python_index\",\\n        save_path: Optional[str] = None,\\n        load: bool = False,\\n        minify_code: bool = False,\\n        remove_docstrings: bool = False,\\n        tokenizer: Optional[tiktoken.Encoding] = None,\\n    ):\\n        # Initialize the MemoryIndex\\n        MemoryIndex.__init__(\\n            self,\\n            name=name,\\n            save_path=save_path,\\n            load=load,\\n            tokenizer=tokenizer,\\n        )\\n        # Initialize the PythonParser\\n        PythonParser.__init__(\\n            self,\\n            directory_path=directory_path,\\n            minify_code=minify_code,\\n            remove_docstrings=remove_docstrings,\\n        )\\n\\n        if not load:\\n            # Extract functions and classes source code\\n            function_source_codes, class_source_codes, _, _ = self.process_directory()\\n            print(\\n                \"Indexing {} functions and {} classes\".format(\\n                    len(function_source_codes), len(class_source_codes)\\n                )\\n            )\\n            # Concatenate function and class source code and index them\\n            codes = function_source_codes + class_source_codes\\n            for code in codes:\\n                self.add_to_index(code)\\n\\n            self.save()\\n',\n",
       "  'from typing import Optional\\n\\nimport tiktoken\\n\\nfrom babydragon.memory.indexes.memory_index import MemoryIndex\\nfrom babydragon.processors.parsers.python_parser import PythonParser\\n\\n\\nclass PythonIndex(MemoryIndex, PythonParser):\\n    def __init__(\\n        self,\\n        directory_path: str,\\n        name: str = \"python_index\",\\n        save_path: Optional[str] = None,\\n        load: bool = False,\\n        minify_code: bool = False,\\n        remove_docstrings: bool = False,\\n        tokenizer: Optional[tiktoken.Encoding] = None,\\n    ):\\n        # Initialize the MemoryIndex\\n        MemoryIndex.__init__(\\n            self,\\n            name=name,\\n            save_path=save_path,\\n            load=load,\\n            tokenizer=tokenizer,\\n        )\\n        # Initialize the PythonParser\\n        PythonParser.__init__(\\n            self,\\n            directory_path=directory_path,\\n            minify_code=minify_code,\\n            remove_docstrings=remove_docstrings,\\n        )\\n\\n        if not load:\\n            # Extract functions and classes source code\\n            function_source_codes, class_source_codes, _, _ = self.process_directory()\\n            print(\\n                \"Indexing {} functions and {} classes\".format(\\n                    len(function_source_codes), len(class_source_codes)\\n                )\\n            )\\n            # Concatenate function and class source code and index them\\n            codes = function_source_codes + class_source_codes\\n            for code in codes:\\n                self.add_to_index(code)\\n\\n            self.save()\\n',\n",
       "  'def __init__(\\n    self,\\n    directory_path: str,\\n    name: str = \"python_index\",\\n    save_path: Optional[str] = None,\\n    load: bool = False,\\n    minify_code: bool = False,\\n    remove_docstrings: bool = False,\\n    tokenizer: Optional[tiktoken.Encoding] = None,\\n):\\n    # Initialize the MemoryIndex\\n    MemoryIndex.__init__(\\n        self,\\n        name=name,\\n        save_path=save_path,\\n        load=load,\\n        tokenizer=tokenizer,\\n    )\\n    # Initialize the PythonParser\\n    PythonParser.__init__(\\n        self,\\n        directory_path=directory_path,\\n        minify_code=minify_code,\\n        remove_docstrings=remove_docstrings,\\n    )\\n\\n    if not load:\\n        # Extract functions and classes source code\\n        function_source_codes, class_source_codes, _, _ = self.process_directory()\\n        print(\\n            \"Indexing {} functions and {} classes\".format(\\n                len(function_source_codes), len(class_source_codes)\\n            )\\n        )\\n        # Concatenate function and class source code and index them\\n        codes = function_source_codes + class_source_codes\\n        for code in codes:\\n            self.add_to_index(code)\\n\\n        self.save()\\n',\n",
       "  'from typing import List, Optional, Union\\n\\nimport libcst as cst\\nfrom python_minifier import minify\\n\\nfrom babydragon.memory.indexes.memory_index import MemoryIndex\\nfrom babydragon.working_memory.parsers.git_processor import GitHubRepoProcessor\\n\\n\\nclass PythonMinifier:\\n    def __init__(self, code: str = None):\\n\\n        self.code = code\\n        self.output_code = None\\n\\n    def minify(self):\\n        if self.code:\\n            self.output_code = self.minify_code(self.code)\\n\\n    def get_minified_code(self):\\n        if not self.output_code:\\n            self.minify()\\n        return self.output_code\\n\\n    @staticmethod\\n    def minify_code(code: str) -> str:\\n        return minify(code)\\n\\n\\nclass PythonDocstringExtractor:\\n    @staticmethod\\n    def extract_docstring(function_def: cst.FunctionDef) -> str:\\n        docstring = None\\n\\n        for stmt in function_def.body.body:\\n            if isinstance(stmt, cst.SimpleStatementLine):\\n                for expr in stmt.body:\\n                    if isinstance(expr, cst.Expr) and isinstance(\\n                        expr.value, cst.SimpleString\\n                    ):\\n                        docstring = expr.value.value.strip(\\'\"\\').strip(\"\\'\")\\n                        break\\n            if docstring is not None:\\n                break\\n\\n        if docstring is not None:\\n            return docstring.strip()\\n        else:\\n            function_name = function_def.name.value\\n            return f\"No docstring provided for function \\'{function_name}\\'. Please add a docstring to describe this function.\"\\n\\n\\nclass GitMemory(MemoryIndex):\\n    def __init__(self, username, repo_name):\\n        super().__init__()\\n        self.username = username\\n        self.repo_name = repo_name\\n        self.parser = GitHubRepoProcessor(username, repo_name)\\n        self.minifier = PythonMinifier()\\n        self.docstring_extractor = PythonDocstringExtractor()\\n        self.directory_parser = None\\n        self.min_code_index = None\\n        self.doc_string_index = None\\n        self.libcst_node_index = None\\n\\n    def create_code_index(self, base_directory):\\n        self.directory_parser = self.parser.process_repo(base_directory)\\n        code_values, code_nodes = self.parser.get_values()\\n        self.code_index = self.init_index(values=code_values)\\n        self.code_index.save()\\n\\n    def create_indexes(self, base_directory):\\n        self.directory_parser = self.parser.process_repo(base_directory)\\n        code_values, code_nodes = self.parser.get_values()\\n        self.code_index = self.init_index(values=code_values)\\n\\n        min_code_values = []\\n        doc_string_values = []\\n        for code_value, code_node in zip(code_values, code_nodes):\\n            minifier = PythonMinifier(code=code_value)\\n            min_code = minifier.get_minified_code()\\n            doc_string = self.docstring_extractor.extract_docstring(code_node)\\n            min_code_values.append(min_code)\\n            doc_string_values.append(doc_string)\\n        self.doc_string_index = self.init_index(values=doc_string_values)\\n        self.min_code_index = self.init_index(values=min_code_values)\\n',\n",
       "  '\\ndef create_indexes(self, base_directory):\\n    self.directory_parser = self.parser.process_repo(base_directory)\\n    code_values, code_nodes = self.parser.get_values()\\n    self.code_index = self.init_index(values=code_values)\\n\\n    min_code_values = []\\n    doc_string_values = []\\n    for code_value, code_node in zip(code_values, code_nodes):\\n        minifier = PythonMinifier(code=code_value)\\n        min_code = minifier.get_minified_code()\\n        doc_string = self.docstring_extractor.extract_docstring(code_node)\\n        min_code_values.append(min_code)\\n        doc_string_values.append(doc_string)\\n    self.doc_string_index = self.init_index(values=doc_string_values)\\n    self.min_code_index = self.init_index(values=min_code_values)\\n',\n",
       "  '# This is the __init__.py file for the package.\\n',\n",
       "  '\\n\\nclass GitMemory(MemoryIndex):\\n    def __init__(self, username, repo_name):\\n        super().__init__()\\n        self.username = username\\n        self.repo_name = repo_name\\n        self.parser = GitHubRepoProcessor(username, repo_name)\\n        self.minifier = PythonMinifier()\\n        self.docstring_extractor = PythonDocstringExtractor()\\n        self.directory_parser = None\\n        self.min_code_index = None\\n        self.doc_string_index = None\\n        self.libcst_node_index = None\\n\\n    def create_code_index(self, base_directory):\\n        self.directory_parser = self.parser.process_repo(base_directory)\\n        code_values, code_nodes = self.parser.get_values()\\n        self.code_index = self.init_index(values=code_values)\\n        self.code_index.save()\\n\\n    def create_indexes(self, base_directory):\\n        self.directory_parser = self.parser.process_repo(base_directory)\\n        code_values, code_nodes = self.parser.get_values()\\n        self.code_index = self.init_index(values=code_values)\\n\\n        min_code_values = []\\n        doc_string_values = []\\n        for code_value, code_node in zip(code_values, code_nodes):\\n            minifier = PythonMinifier(code=code_value)\\n            min_code = minifier.get_minified_code()\\n            doc_string = self.docstring_extractor.extract_docstring(code_node)\\n            min_code_values.append(min_code)\\n            doc_string_values.append(doc_string)\\n        self.doc_string_index = self.init_index(values=doc_string_values)\\n        self.min_code_index = self.init_index(values=min_code_values)\\n',\n",
       "  '\\n\\nclass PythonMinifier:\\n    def __init__(self, code: str = None):\\n\\n        self.code = code\\n        self.output_code = None\\n\\n    def minify(self):\\n        if self.code:\\n            self.output_code = self.minify_code(self.code)\\n\\n    def get_minified_code(self):\\n        if not self.output_code:\\n            self.minify()\\n        return self.output_code\\n\\n    @staticmethod\\n    def minify_code(code: str) -> str:\\n        return minify(code)\\n',\n",
       "  'def __init__(\\n    self,\\n    base_directory: str,\\n    username=None,\\n    repo_name=None,\\n    code_parsers=None,\\n    minify_code: bool = False,\\n    remove_docstrings: bool = False,\\n):\\n    self.username = username\\n    self.repo_name = repo_name\\n    self.base_directory = base_directory\\n    self.github = Github()\\n    self.repo = self.github.get_repo(f\"{username}/{repo_name}\")\\n    repo_path = self.clone_repo(self.repo.clone_url)\\n\\n    OsProcessor.__init__(self, repo_path)\\n    self.code_parsers = code_parsers or [\\n        PythonParser(\\n            repo_path, minify_code=minify_code, remove_docstrings=remove_docstrings\\n        )\\n    ]\\n',\n",
       "  '\\ndef __init__(\\n    self,\\n    model: str = None,\\n    max_output_tokens: int = 1000,\\n    system_prompt: str = None,\\n    user_prompt: str = None,\\n    index_dict: Optional[Dict[str,MemoryIndex]] = None,\\n    max_index_memory: int = 1000,\\n) -> None:\\n    BaseChat.__init__(self, model=model, max_output_tokens=max_output_tokens)\\n    Prompter.__init__(self, system_prompt=system_prompt, user_prompt=user_prompt)\\n    self.index_dict = index_dict\\n    self.setup_indices(max_index_memory)\\n'],\n",
       " [0.81691384,\n",
       "  0.81105536,\n",
       "  0.78589565,\n",
       "  0.76883537,\n",
       "  0.767285,\n",
       "  0.7568508,\n",
       "  0.75186425,\n",
       "  0.7464661,\n",
       "  0.7445079,\n",
       "  0.74320173],\n",
       " array([[280,  91,  90, 268, 267,   0, 314, 299, 150,  18]], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babyindex.faiss_query(\"PythonIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to call OpenAI API...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Question: \n",
       " sounds great can you show me how to create a chatbot step by step using fifothread to automatically debug python code?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " #### Anwser: \n",
       " The given hints provide an overview of using the FifoThread class as a chatbot memory management component. However, it does not directly cover how to create a chatbot to debug Python code. Nonetheless, I'll do my best to provide you with a step-by-step guide to create a Python code debugging chatbot using the FifoThread class.\n",
       "\n",
       "1. Import necessary modules and classes:\n",
       "\n",
       "```python\n",
       "import copy\n",
       "from IPython.display import Markdown, display\n",
       "from babydragon.memory.threads.base_thread import BaseThread\n",
       "from babydragon.utils.oai import check_dict\n",
       "# Add any additional imports needed for code debugging and chatbot functionalities\n",
       "```\n",
       "\n",
       "2. Modify the FifoThread class to account for debugging functionalities.\n",
       "\n",
       "The hints provided do not include the full implementation of the chatbot. You can expand the existing FifoThread class using the examples in the hints to add debugging features. For example, you may create a function that receives code as input, processes it, detects issues, and provides feedback.\n",
       "\n",
       "```python\n",
       "class DebuggingFifoThread(FifoThread):\n",
       "    def __init__(self, *args, **kwargs):\n",
       "        super().__init__(*args, **kwargs)\n",
       "        self.debugging_features = YourDebuggingSystem()\n",
       "\n",
       "    def debug_code(self, code):\n",
       "        # Implement your debugging functionality here\n",
       "        feedback = self.debugging_features.process(code)\n",
       "        return feedback\n",
       "```\n",
       "\n",
       "3. Create a dialogue system for the chatbot.\n",
       "\n",
       "A proper dialogue system is beyond the provided hints. But for a simple dialogue system, you can create a function that processes the user input and triggers the debugging upon encountering Python code.\n",
       "\n",
       "```python\n",
       "class DebuggingChatBot:\n",
       "    def __init__(self):\n",
       "        self.memory_thread = DebuggingFifoThread()\n",
       "\n",
       "    def process_input(self, text):\n",
       "        response = \"Sorry, I couldn't process your request.\"\n",
       "        if \"debug\" in text:  # adjust this condition as needed\n",
       "            debug_result = self.memory_thread.debug_code(text)\n",
       "            response = \"Here are the debugging results: \\n{}\".format(debug_result)\n",
       "        return response\n",
       "```\n",
       "\n",
       "4. Build the chatbot user interface.\n",
       "\n",
       "Depending on your choice, you can use text input, command-line input, or Gradio/other libraries for an interactive chatbot interface.\n",
       "\n",
       "You can now create an instance of the chatbot class and use whatever interface you have chosen to take user input, process it, and provide feedback through the chatbot's dialogue system.\n",
       "\n",
       "Keep in mind that while this guide gives you an idea of how to proceed, you'll need to adjust the code and explore additional resources to create a fully functional debug chatbot. The hints provided are related to implementing the FifoThread memory management class and do not cover the complete process of chatbot development with debugging capabilities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The given hints provide an overview of using the FifoThread class as a chatbot memory management component. However, it does not directly cover how to create a chatbot to debug Python code. Nonetheless, I\\'ll do my best to provide you with a step-by-step guide to create a Python code debugging chatbot using the FifoThread class.\\n\\n1. Import necessary modules and classes:\\n\\n```python\\nimport copy\\nfrom IPython.display import Markdown, display\\nfrom babydragon.memory.threads.base_thread import BaseThread\\nfrom babydragon.utils.oai import check_dict\\n# Add any additional imports needed for code debugging and chatbot functionalities\\n```\\n\\n2. Modify the FifoThread class to account for debugging functionalities.\\n\\nThe hints provided do not include the full implementation of the chatbot. You can expand the existing FifoThread class using the examples in the hints to add debugging features. For example, you may create a function that receives code as input, processes it, detects issues, and provides feedback.\\n\\n```python\\nclass DebuggingFifoThread(FifoThread):\\n    def __init__(self, *args, **kwargs):\\n        super().__init__(*args, **kwargs)\\n        self.debugging_features = YourDebuggingSystem()\\n\\n    def debug_code(self, code):\\n        # Implement your debugging functionality here\\n        feedback = self.debugging_features.process(code)\\n        return feedback\\n```\\n\\n3. Create a dialogue system for the chatbot.\\n\\nA proper dialogue system is beyond the provided hints. But for a simple dialogue system, you can create a function that processes the user input and triggers the debugging upon encountering Python code.\\n\\n```python\\nclass DebuggingChatBot:\\n    def __init__(self):\\n        self.memory_thread = DebuggingFifoThread()\\n\\n    def process_input(self, text):\\n        response = \"Sorry, I couldn\\'t process your request.\"\\n        if \"debug\" in text:  # adjust this condition as needed\\n            debug_result = self.memory_thread.debug_code(text)\\n            response = \"Here are the debugging results: \\\\n{}\".format(debug_result)\\n        return response\\n```\\n\\n4. Build the chatbot user interface.\\n\\nDepending on your choice, you can use text input, command-line input, or Gradio/other libraries for an interactive chatbot interface.\\n\\nYou can now create an instance of the chatbot class and use whatever interface you have chosen to take user input, process it, and provide feedback through the chatbot\\'s dialogue system.\\n\\nKeep in mind that while this guide gives you an idea of how to proceed, you\\'ll need to adjust the code and explore additional resources to create a fully functional debug chatbot. The hints provided are related to implementing the FifoThread memory management class and do not cover the complete process of chatbot development with debugging capabilities.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.reply(\"sounds great can you show me how to create a chatbot step by step using fifothread to automatically debug python code?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Port 7860 is in use. If a gradio.Blocks is running on the port, you can close() it or gradio.close_all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tommaso\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\networking.py:119\u001b[0m, in \u001b[0;36mstart_server\u001b[1;34m(blocks, server_name, server_port, ssl_keyfile, ssl_certfile, ssl_keyfile_password)\u001b[0m\n\u001b[0;32m    118\u001b[0m s \u001b[39m=\u001b[39m socket\u001b[39m.\u001b[39msocket()\n\u001b[1;32m--> 119\u001b[0m s\u001b[39m.\u001b[39;49mbind((LOCALHOST_NAME, server_port))\n\u001b[0;32m    120\u001b[0m s\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chatbot\u001b[39m.\u001b[39;49mgradio()\n",
      "File \u001b[1;32mc:\\Users\\Tommaso\\Documents\\Dev\\BabyDragon\\babydragon\\chat\\base_chat.py:247\u001b[0m, in \u001b[0;36mBaseChat.gradio\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m txt\u001b[39m.\u001b[39msubmit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_text, [txt, state], [chatbot, state])\n\u001b[0;32m    246\u001b[0m txt\u001b[39m.\u001b[39msubmit(\u001b[39mlambda\u001b[39;00m: \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m, txt)\n\u001b[1;32m--> 247\u001b[0m demo\u001b[39m.\u001b[39;49mlaunch(server_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlocalhost\u001b[39;49m\u001b[39m\"\u001b[39;49m, server_port\u001b[39m=\u001b[39;49m\u001b[39m7860\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Tommaso\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py:1397\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[1;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, quiet, show_api, file_directories, _frontend)\u001b[0m\n\u001b[0;32m   1393\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[0;32m   1394\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mRerunning server... use `close()` to stop if you need to change `launch()` parameters.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m----\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1395\u001b[0m         )\n\u001b[0;32m   1396\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1397\u001b[0m     server_name, server_port, local_url, app, server \u001b[39m=\u001b[39m networking\u001b[39m.\u001b[39;49mstart_server(\n\u001b[0;32m   1398\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1399\u001b[0m         server_name,\n\u001b[0;32m   1400\u001b[0m         server_port,\n\u001b[0;32m   1401\u001b[0m         ssl_keyfile,\n\u001b[0;32m   1402\u001b[0m         ssl_certfile,\n\u001b[0;32m   1403\u001b[0m         ssl_keyfile_password,\n\u001b[0;32m   1404\u001b[0m     )\n\u001b[0;32m   1405\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_name \u001b[39m=\u001b[39m server_name\n\u001b[0;32m   1406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_url \u001b[39m=\u001b[39m local_url\n",
      "File \u001b[1;32mc:\\Users\\Tommaso\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\networking.py:122\u001b[0m, in \u001b[0;36mstart_server\u001b[1;34m(blocks, server_name, server_port, ssl_keyfile, ssl_certfile, ssl_keyfile_password)\u001b[0m\n\u001b[0;32m    120\u001b[0m         s\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    121\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m--> 122\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m    123\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPort \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is in use. If a gradio.Blocks is running on the port, you can close() it or gradio.close_all().\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    124\u001b[0m                 server_port\n\u001b[0;32m    125\u001b[0m             )\n\u001b[0;32m    126\u001b[0m         )\n\u001b[0;32m    127\u001b[0m     port \u001b[39m=\u001b[39m server_port\n\u001b[0;32m    129\u001b[0m url_host_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m server_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.0.0.0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m server_name\n",
      "\u001b[1;31mOSError\u001b[0m: Port 7860 is in use. If a gradio.Blocks is running on the port, you can close() it or gradio.close_all()."
     ]
    }
   ],
   "source": [
    "chatbot.gradio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
