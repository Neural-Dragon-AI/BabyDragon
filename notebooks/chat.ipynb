{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat and Prompter Class\n",
    "In this tutorial, we will demonstrate how to use the Chat and Prompter classes in the BabyDragon chatbot framework. These classes allow you to create a chatbot with a system and user prompt, and the ability to handle queries to multiple MemoryIndex through the index_dict.\n",
    "\n",
    "### 1. Import necessary modules\n",
    "Before we begin, let's import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Union\n",
    "from babydragon.chat.base_chat import BaseChat, Prompter\n",
    "from babydragon.chat.prompts.default_prompts import (INDEX_HINT_PROMPT,\n",
    "                                                     INDEX_SYSTEM_PROMPT,\n",
    "                                                     QUESTION_INTRO)\n",
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "from babydragon.chat.chat import Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Chat class\n",
    "Create an instance of the Chat class with the desired parameters. In this example, we will use the default model, gpt-3.5-turbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_instance = Chat(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the system and user prompts\n",
    "Define the system and user prompts to guide the chatbot. You can either use the default prompts provided by the framework or define your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"I am a helpful assistant. How may I help you today?\"\n",
    "def user_prompt(message: str) -> str:\n",
    "    return f\"User: {message}\"\n",
    "\n",
    "chat_instance.update_system_prompt(system_prompt)\n",
    "chat_instance.update_user_prompt(user_prompt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Send a message to the chatbot\n",
    "Now, you can send a message to the chatbot and receive a response. In this example, we will ask the chatbot a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"What is the capital of France?\"\n",
    "response = chat_instance.reply(message)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using MemoryIndex with the Chat class\n",
    "You can use MemoryIndex with the Chat class to handle queries and store relevant information. First, let's import the necessary modules and create a MemoryIndex instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babydragon.memory.indexes.memory_index import MemoryIndex\n",
    "memory_index = MemoryIndex()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, add some key-value pairs to the memory index. In this example, we will add information about the capitals of a few countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_index.add_to_index(\"What is the capital of France? The capital of France is Paris.\")\n",
    "memory_index.add_to_index(\"What is the capital of Germany? The capital of Germany is Berlin.\")\n",
    "memory_index.add_to_index(\"What is the capital of Italy? The capital of Italy is Rome.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a new instance of the Chat class and set the index_dict parameter to include the MemoryIndex instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_instance_with_index = Chat(model=\"gpt-3.5-turbo\", index_dict={\"capitals\": memory_index})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the current index for the chatbot to use when providing hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_instance_with_index.set_current_index(\"capitals\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, send a message to the chatbot using the MemoryIndex instance for hints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"What is the capital of France?\"\n",
    "response = chat_instance_with_index.reply(message)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babydragon.models.generators.cohere import cohere_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = cohere_response(prompt = \"Hello\", model = \"command-nightly\", max_tokens = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
